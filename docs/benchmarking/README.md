# ProvChain-Org Benchmarking Guide

Complete guide to performance testing and benchmarking ProvChain-Org.

## ðŸŽ¯ Quick Links

- [Portable Benchmark Toolkit](#portable-benchmark-toolkit) - One-command performance testing
- [Academic Benchmarking](#academic-benchmarking) - Research publication benchmarks
- [Results Archive](#results-archive) - Historical benchmark data

---

## ðŸ“¦ Portable Benchmark Toolkit

### What Is It?

A self-contained, portable toolkit for running performance comparisons against:
- **Neo4j** (graph database)
- **Ethereum** (blockchain)
- **Hyperledger Fabric** (enterprise blockchain)
- **FlureeDB** (RDF database)

### Quick Start

```bash
cd ../benchmark-toolkit
./run.sh
```

The toolkit automatically:
- âœ… Detects your hardware capabilities
- âœ… Configures optimal settings
- âœ… Runs comprehensive benchmarks
- âœ… Generates comparison reports
- âœ… Displays real-time visualizations

### Features

- **Auto-detection**: Adapts to 4GB-32GB+ RAM machines
- **One-command execution**: No manual configuration needed
- **Portable**: Copy anywhere, runs on any machine with Docker
- **Comprehensive**: Query performance, write throughput, permission overhead

### Hardware Profiles

| Profile | RAM | CPU | Dataset | Time | Best For |
|---------|-----|-----|---------|------|----------|
| **Low** | 4GB | 2 cores | 100 tx | ~5 min | Development laptops |
| **Medium** | 8GB | 4 cores | 1,000 tx | ~15 min | Standard testing âœ… |
| **High** | 16GB | 8 cores | 5,000 tx | ~45 min | Powerful workstations |
| **Ultra** | 32GB+ | 16+ cores | 10,000 tx | ~2 hours | Servers, cloud |

### Accessing Results

After running benchmarks:

- **Grafana Dashboard**: http://localhost:3000 (admin/admin)
- **Summary Report**: `../benchmark-toolkit/results/summary.md`
- **Raw Data**: `../benchmark-toolkit/results/benchmark_results.csv`

### Full Documentation

See the [benchmark-toolkit README](../../benchmark-toolkit/README.md) for complete documentation including:
- [Quick Start Guide](../../benchmark-toolkit/QUICKSTART.md)
- [Deployment Guide](../../benchmark-toolkit/DEPLOYMENT_GUIDE.md)
- [Portability Guide](../../benchmark-toolkit/PORTABILITY.md)

---

## ðŸ”¬ Academic Benchmarking

### Publication-Ready Benchmarks

For research publications and thesis analysis:

#### Planning & Methodology
- **Research Plan**: [BENCHMARKING_PLAN.md](BENCHMARKING_PLAN.md)
  - Academic benchmarking methodology
  - Target journals (IF > 8.0)
  - Publication strategy

- **Methodology**: [Performance Testing Guide](../performance-testing-guide.md)
  - Testing procedures
  - Metrics collection
  - Statistical analysis

- **Results**: [BENCHMARK_RESULTS_SUMMARY.md](BENCHMARK_RESULTS_SUMMARY.md)
  - Historical benchmark data
  - Performance trends
  - Comparative analysis

#### Criterion Benchmarks

Micro-benchmarks for specific components:

```bash
# Run all Criterion benchmarks
cargo bench

# Run with baseline comparison
cargo bench -- --save-baseline main

# Compare against baseline
cargo bench -- --baseline main
```

See [CRITERION_BENCHMARKING_GUIDE.md](CRITERION_BENCHMARKING_GUIDE.md) for details.

#### Trace Optimization

- **Results**: [TRACE_OPTIMIZATION_BENCHMARK_RESULTS.md](TRACE_OPTIMIZATION_BENCHMARK_RESULTS.md)
- **Focus**: Frontier Reduction and Pivot Selection algorithms
- **Metrics**: Microsecond-latency product tracing

---

## ðŸ“ˆ Results Archive

### Recent Benchmarks

#### 2024-01-04: Query Performance vs Neo4j
- **Result**: 33.4% faster SPARQL queries
- **Metric**: 45.23ms vs 67.89ms (multi-hop traceability)
- **Dataset**: 1,000 RDF triples (supply chain)

#### 2024-01-03: Write Throughput Comparison
- **Result**: 58% higher throughput
- **Metric**: 150 tx/sec vs 95 tx/sec (Neo4j)
- **Test**: Sustained write load

### Historical Data

See `../benchmark-toolkit/results/` directory for detailed benchmark results from all runs.

### Key Metrics Summary

| Metric | ProvChain-Org | Neo4j | Improvement |
|--------|---------------|-------|-------------|
| Query Latency | 45.23ms | 67.89ms | 33.4% faster |
| Throughput | 150 tx/sec | 95 tx/sec | 58% higher |
| Permission Overhead | <10% | N/A | Minimal impact |
| Cross-Chain Sync | <5 sec | N/A | Feature unique |

---

## ðŸŽ“ Thesis Integration

### Using Benchmarks for Thesis

#### Step 1: Generate Results

```bash
cd ../benchmark-toolkit
./run.sh medium  # Standard testing profile
```

#### Step 2: Export Data

Results are automatically saved to:
- `results/summary.md` - Human-readable summary
- `results/benchmark_results.json` - Raw data
- `results/benchmark_results.csv` - For Excel/analysis

#### Step 3: Create Figures

1. Open Grafana: http://localhost:3000
2. Navigate to benchmark dashboard
3. Click **Share** > **Export**
4. Save as PNG for thesis figures

#### Step 4: Document Metrics

Use metrics from `summary.md` in your thesis:

**Sample Thesis Text**:
> "We evaluated ProvChain-Org against Neo4j graph database using a standardized RDF dataset containing 1,000 triples representing food supply chain transactions. Benchmarks were conducted on a system with 8GB RAM and 4 CPU cores, using 10 iterations per test. ProvChain-Org demonstrated 33.4% faster query performance for multi-hop traceability queries (45.23ms vs 67.89ms). Transaction throughput reached 150 tx/sec compared to Neo4j's 95 tx/sec, representing a 58% improvement."

### Key Metrics for Thesis

1. **Query Performance**
   - SPARQL latency comparison
   - Multi-hop traceability speed
   - Complex query execution time

2. **Throughput**
   - Transactions per second
   - Concurrent write performance
   - Burst handling capability

3. **Overhead Analysis**
   - Permission control impact
   - Encryption overhead
   - Consensus protocol comparison

4. **Scalability**
   - Performance vs dataset size
   - Resource utilization
   - Horizontal scaling

---

## ðŸ”— Related Resources

### Documentation
- [Main Project README](../../README.md)
- [Deployment Guides](../deployment/)
- [API Documentation](../api/)
- [Research Context](../research/)

### Toolkit Documentation
- [Full Guide](../../benchmark-toolkit/README.md)
- [Quick Start](../../benchmark-toolkit/QUICKSTART.md)
- [Portability](../../benchmark-toolkit/PORTABILITY.md)

### Developer Resources
- [Contributing Guide](../developer/CONTRIBUTING.md)
- [Architecture Overview](../developer/architecture.md)
- [Testing Guide](../developer/testing.md)

---

## ðŸš€ Quick Reference Commands

### Run Benchmarks

```bash
# Quick test (5 minutes)
cd ../benchmark-toolkit && ./run.sh low

# Standard test (15 minutes) - RECOMMENDED
./run.sh medium

# Full test (45 minutes)
./run.sh high

# Extensive test (2 hours)
./run.sh ultra
```

### Component Benchmarks

```bash
# Criterion micro-benchmarks
cargo bench

# Load testing
cargo test --test load_tests --release -- --ignored

# Trace optimization benchmarks
cargo bench --bench trace_optimization
```

### Access Services

```bash
# Grafana Dashboard
open http://localhost:3000

# ProvChain API
curl http://localhost:8080/health

# Neo4j Browser
open http://localhost:7474
```

---

## ðŸ“ž Troubleshooting

### Common Issues

**Problem**: Docker not running
```bash
# Start Docker service
sudo systemctl start docker  # Linux
# Or start Docker Desktop     # macOS/Windows
```

**Problem**: Port already in use
```bash
# Check what's using the port
lsof -i :8080

# Change ports in benchmark-toolkit/docker-compose.yml
```

**Problem**: Out of memory
```bash
# Use lower profile
cd ../benchmark-toolkit
./run.sh low
```

**Problem**: No results generated
```bash
# Check service health
curl http://localhost:8080/health
curl http://localhost:7474

# View logs
cd ../benchmark-toolkit
docker-compose logs -f
```

---

**Last Updated**: 2024-01-04
**Toolkit Version**: 1.0.0
**ProvChain-Org Version**: 1.0.0
